# -*- coding: utf-8 -*-
"""
Created on Tue May 29 11:31:06 2018

@author: jhonarox
"""

# Data Preprocessing Template

# Importing the libraries
import numpy as np
import pandas as pd
import sqlite3


def check(regressor, data_input):
    return regressor.predict(data_input);


def pca(X):
    # PCA
    from sklearn.decomposition import PCA
    pca = PCA(n_components=1)
    X = pca.fit_transform(X)
    return X


def data_preprocess(input_apk):
    # Insert APK
    from androguard import misc
    a, d, dx = misc.AnalyzeAPK(input_apk)
    input_apk_permission = a.get_permissions()
    input_apk_permission = pd.DataFrame(input_apk_permission)
    input_apk_permission.columns = ['Name']

    # Connection to database
    connection = sqlite3.connect("AndrosecData.sqlite")

    # Importing the dataset
    permission_table = pd.read_sql_query("""
                                         SELECT * FROM Permission;
                                         """, connection)
    permission_table_manifest = pd.read_sql_query("""
                                         SELECT * FROM Android_Manifest_Permission;
                                         """, connection)
    join_1 = pd.read_sql_query(""" SELECT Version.versionID, fuzzy_risk
                                FROM Version
                                INNER JOIN Vulnerability
                                ON Version.versionID = Vulnerability.versionID
                                ; """, connection)
    join_2 = pd.read_sql_query(""" SELECT UnderPermission.VersionID, Permission.PermissionID
                               FROM Permission
                               JOIN UnderPermission
                               ON UnderPermission.permissionID = Permission.PermissionID
                                ; """, connection)

    join_3 = pd.read_sql_query(""" SELECT OverPermission.VersionID, Permission.PermissionID
                               FROM Permission
                               JOIN OverPermission
                               ON OverPermission.permissionID = Permission.PermissionID
                                ; """, connection)

    connection.close()

    # Input Data Preprocessing
    data_input = pd.merge(permission_table, input_apk_permission, left_on='name', right_on='Name', how='inner')
    data_input = pd.merge(permission_table_manifest, input_apk_permission, left_on='Permission', right_on='Name',
                          how='inner')
    data_input = data_input.drop('Name', axis=1)
    data_input['VersionID'] = np.nan
    data_input = data_input.pivot(index='VersionID', columns='Permission')

    return permission_table, permission_table_manifest, join_1, join_2, join_3, input_apk_permission, data_input


def train(dataset, data_input):
    # X Data
    X = dataset.iloc[:, 2:].values
    # Y Data
    y = dataset.iloc[:, 1].values

    X = pca(X)
    data_input = pca(data_input)

    # SVM
    from sklearn.svm import SVR
    regressor = SVR(kernel='rbf')
    regressor.fit(X, y)
    # Predict Output
    return check(regressor, data_input);


def main(input_apk):
    permission_table, permission_table_manifest, join_1, join_2, join_3, input_apk_permission, data_input = data_preprocess(input_apk)

    # Prepare dataset
    dataset_1 = pd.merge(join_2, join_1)
    dataset_2 = pd.merge(join_3, join_1)

    # Dataset_1
    temp = dataset_1.pivot(index='versionID', columns='permissionID')
    temp = temp.fillna(0)
    temp[temp > 0] = 1
    dataset_1 = pd.merge(dataset_1, temp, left_on='versionID', right_index=True)
    dataset_1 = dataset_1.drop('permissionID', axis=1)
    dataset_1 = dataset_1.drop_duplicates(subset=['versionID', 'fuzzy_risk_x'], keep=False)

    # Dataset_2
    temp = dataset_2.pivot(index='versionID', columns='permissionID')
    temp = temp.fillna(0)
    temp[temp > 0] = 1
    dataset_2 = pd.merge(dataset_2, temp, left_on='versionID', right_index=True)
    dataset_2 = dataset_2.drop('permissionID', axis=1)
    dataset_2 = dataset_2.drop_duplicates(subset=['versionID', 'fuzzy_risk_x'], keep=False)

    result_1 = train(dataset_1, data_input)
    result_2 = train(dataset_2, data_input)
    return (result_1 + result_2)/2;